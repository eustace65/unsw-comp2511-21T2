# Marking Criteria

During assessment, we will look at each category in its entirety as well as the individual components which we have described here. The components of each category are not necessarily of equal importance.

## Milestone 1

| Criteria    | Description |
|:----------- |:----- |
| <b>Requirements Analysis (30%)</b> |
| Epic Stories | Do the epic stories encompass all the major areas of the requirements? Are they logically segmented? Are they abstracted away from specific stories/requirements? |
| User Stories | Do the user stories follow the correct structure (Role, Goal, Benefit)? Do you model the requirements accurately? Are the benefits provided plausible and realistic? Is each story specific to a single conceptual need? |
| Acceptance Criteria | Are the criteria in the correct format (Yes/No, or Given-When-Then)? Are they achieveable and specific? Are they atomic? Are there any requirements missing from the criteira?|
| Story Points | Is the allocation of story points logical and understandable? | Priority | Are stories prioritised clearly? Do the priorities make logical sense? |
| <b>Assumptions (10%)</b> |
| Quality | Are the assumptions provided of good quality? Do you clear up genuine ambiguities in the spec? |
| Scope | Are there any key assumptions missing? Do the assumptions clarify a range of requirements? Do the assumptions reduce the scope of the spec?
| <b>Domain Model & UML Diagram (20%)</b> | Things to consider include, but are not limited to: <ul><li>Do your inheritance relationships make logical sense?</li> <li>Have you obeyed LSP?</li> <li>Have you used interfaces vs abstract classes appropriately?</li> <li>Are the aggregation and composition relationships and cardinalities shown on the UML logical and appropriate?</li> <li>Are all classes single responsibility? Is there a lot of logic in the main Game class(es) or is it split up?</li> <li>Are there any redundant classes / data classes?</li> <li>Have all the appropriate entities been modelled as classes, or is data grouped arbitrarily in JSON objects/strings/arrays?</li> <li>Is the diagram correctly formatted?</li></ul> Note that if you are not using all of these concepts such as inheritance and/or aggregation, then you will not lose marks. |
| <b>User Interface Design (20%)</b> |
| Formatting | Is the user interface design neatly presented? |
| User Interactions | Are the user interactions clearly articulated? Are they logical and simple? |
| Overall User Experience | Use of colour schemes, logical layout, accessibility. Does it look nice and like a product that you'd want to use? |
| <b>Project Management (20%)</b> |
| Sequencing of Tasks | Are the tasks on the timeline sequenced logically (e.g. prerequisite epics/stories are completed first) Do you correspond to user stories? Does the sequencing correspond to priority the story priorities? |
| Allocation of Tasks | Are tasks allocated to all team members approx equally?  Do the task allocations seem feasible? Is the allocation logical (e.g. 1 person handles an epic) |
| Timespan of Tasks | Does the time span of tasks align with the allocation of story points? Are these timespan predictions reasonable? |
| Minutes | Have you demonstrated the use of meeting minutes? Version history is needed to show that the minutes weren't faked. |

## Milestone 2

| Criteria    | Description |
|:----------- |:----- |
| <b>Backend (30%)</b> |
| Breadth of Implementation | How much of the client requirements has been implemented and is working correctly?  |
| Code Style | See Section 6.0 |
| Assumptions | Has the group added good assumptions to your list since Milestone 1 that shows increased understanding of the requirements? |
| <b>Frontend (15%)</b> |
| Works on Frontend | How well does the group's code work when run on the frontend during the demo?  |
| Overall User Experience | Does the user interface provide a nice playing experience? Is it accessible, logically laid out and easy to use? |
| Modification of Starter Code | Has JavaFX been used effectively to implement the remaining features? Or has the group built your frontend around the starter code? |
| <b>Domain Model & UML Diagram (25%)</b> | Things to consider include, but are not limited to: <ul><li>Have you made use of at least three design patterns taught?</li> <li>Do these patterns improve the design or are they forced on?</li> <li>Are the patterns modelled appropriately?</li> <li>Have you used the right patterns (e.g. state vs strategy)?</li> <li>Do your inheritance relationships make logical sense?</li> <li>Have you obeyed LSP?</li> <li>Have you used interfaces vs abstract classes appropriately?</li> <li>Are the aggregation and composition relationships and cardinalities shown on the UML logical and appropriate?</li> <li>Are all classes single responsibility? Is there a lot of logic in the main Game class(es) or is it split up?</li> <li>Are there any redundant classes / data classes?</li> <li>Have all the appropriate entities been modelled as classes, or is data grouped arbitrarily in JSON objects/strings/arrays?</li> <li>Is the diagram correctly formatted?</li></ul> Note that if you are not using all of these concepts such as inheritance and/or aggregation, then you will not lose marks.|
| <b>Testing (20%)</b> |
| Coverage | 90% coverage of the backend code will give you full marks in this section. |
| Test Design | Do you have a mix of unit and integration tests? Are the tests structured logically / intelligently? |
| Test Clarity | Are your tests understandable? Logical commenting? Good variables? |
| <b>Git & Project Management (10%)</b> |
| Git Commits & Merge Requests | Commit messages are meaningful, aren't repeated, evidence of merge requests into master, master is merged into regularly |
| Task Board | The board shows the truth of the team's progress, tasks are assigned and moved across the columns |
| Minutes | Have you demonstrated the use of meeting minutes? Version history is needed to show that the minutes weren't faked. |

## Milestone 3

| Criteria    | Description |
|:----------- |:----- |
| <b>Backend (30%)</b> |
| Integration of Updated Requirements | How much of the updated client requirements has been implemented and is working correctly?   |
| Breadth & Depth of Extensions | Has the group implemented a range of extensions (breadth) that are complex (depth) and at least some were challenging to implement? Assumptions file can be used to assist marking here |
| Code Style | See Section 6.0 |
| <b>Frontend (20%)</b> |
| Works on Frontend | How well does the group's code work when run on the frontend during the demo?  |
| Overall User Experience | Does the user interface provide a nice playing experience? Is it accessible, logically laid out and easy to use? |
| Enhancement of Extensions | How well do the extensions add to the user's experience and enjoyment when playing the game? |
| <b>Domain Model & UML Diagram (20%)</b> | Things to consider include, but are not limited to: <ul><li>Have you made use of at least four design patterns taught?</li> <li>Do these patterns improve the design or are they forced on?</li> <li>Are the patterns modelled appropriately?</li> <li>Have you used the right patterns (e.g. state vs strategy)?</li> <li>Do your inheritance relationships make logical sense?</li> <li>Have you obeyed LSP?</li> <li>Have you used interfaces vs abstract classes appropriately?</li> <li>Are the aggregation and composition relationships and cardinalities shown on the UML logical and appropriate?</li> <li>Are all classes single responsibility? Is there a lot of logic in the main Game class(es) or is it split up?</li> <li>Are there any redundant classes / data classes?</li> <li>Have all the appropriate entities been modelled as classes, or is data grouped arbitrarily in JSON objects/strings/arrays?</li> <li>Is the diagram correctly formatted?</li></ul> Note that if you are not using all of these concepts such as inheritance and/or aggregation, then you will not lose marks. |
| <b>Testing (15%)</b> |
| Coverage | 90% coverage of the backend code will give you full marks in this section. |
| Test Design | Do you have a mix of unit and integration tests? Are the tests structured logically / intelligently? |
| Test Clarity | Do you understand what your tests are doing? Logical commenting? Good variables? |
| <b>Git & Project Management (15%)</b> |
| User Stories | Has the task board been updated with the new user stories, acceptance criteria, priorities and story points for the new requirements/extensions? How well are these done? |
| Git Commits & Merge Requests | Commit messages are meaningful, aren't repeated, evidence of merge requests into master, master is merged into regularly |
| Task Board & Timeline | The board shows the truth of the team's progress, tasks are assigned and moved across the columns. Timeline has been updated for new requirements. |
| Minutes | Have you demonstrated the use of meeting minutes? Version history is needed to show that the minutes weren't faked. |
